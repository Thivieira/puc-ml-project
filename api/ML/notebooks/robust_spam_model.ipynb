{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Robust Spam Model - Jupyter Notebook\n",
        "\n",
        "Este notebook demonstra o treinamento e avalia√ß√£o do modelo robusto de classifica√ß√£o de spam SMS.\n",
        "\n",
        "## Caracter√≠sticas do Modelo Robusto:\n",
        "- Extra√ß√£o de features espec√≠ficas para spam\n",
        "- Pipeline com TF-IDF e Random Forest\n",
        "- Feature engineering avan√ßado\n",
        "- Avalia√ß√£o detalhada de performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa√ß√µes necess√°rias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carregamento e An√°lise Explorat√≥ria dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dados\n",
        "url = \"https://gist.githubusercontent.com/Thivieira/aa018594f9a6e05e005f7c3f3136f4f2/raw/7c2b4aa3cd212c369471db6ce26119227c4a38e4/SMSSpamCollection\"\n",
        "df = pd.read_csv(url, sep=\"\\t\", header=None, names=['label', 'text'])\n",
        "df['target'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "print(f\"üìä Dataset carregado: {len(df)} mensagens\")\n",
        "print(f\"üìà Distribui√ß√£o de classes:\")\n",
        "print(df['label'].value_counts())\n",
        "print(f\"\\nüìä Estat√≠sticas b√°sicas:\")\n",
        "print(f\"- Spam: {df['target'].sum()} ({df['target'].sum()/len(df)*100:.1f}%)\")\n",
        "print(f\"- Ham: {len(df)-df['target'].sum()} ({(len(df)-df['target'].sum())/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lise explorat√≥ria\n",
        "df['text_length'] = df['text'].str.len()\n",
        "df['word_count'] = df['text'].str.split().str.len()\n",
        "df['uppercase_count'] = df['text'].str.count(r'[A-Z]')\n",
        "df['exclamation_count'] = df['text'].str.count('!')\n",
        "df['digit_count'] = df['text'].str.count(r'\\d')\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('An√°lise Explorat√≥ria - Caracter√≠sticas por Classe', fontsize=16)\n",
        "\n",
        "axes[0,0].hist(df[df['target']==0]['text_length'], alpha=0.7, label='Ham', bins=30)\n",
        "axes[0,0].hist(df[df['target']==1]['text_length'], alpha=0.7, label='Spam', bins=30)\n",
        "axes[0,0].set_title('Comprimento do Texto')\n",
        "axes[0,0].set_xlabel('Comprimento')\n",
        "axes[0,0].legend()\n",
        "\n",
        "axes[0,1].hist(df[df['target']==0]['word_count'], alpha=0.7, label='Ham', bins=30)\n",
        "axes[0,1].hist(df[df['target']==1]['word_count'], alpha=0.7, label='Spam', bins=30)\n",
        "axes[0,1].set_title('Contagem de Palavras')\n",
        "axes[0,1].set_xlabel('N¬∫ de Palavras')\n",
        "axes[0,1].legend()\n",
        "\n",
        "axes[0,2].hist(df[df['target']==0]['uppercase_count'], alpha=0.7, label='Ham', bins=30)\n",
        "axes[0,2].hist(df[df['target']==1]['uppercase_count'], alpha=0.7, label='Spam', bins=30)\n",
        "axes[0,2].set_title('Caracteres Mai√∫sculos')\n",
        "axes[0,2].set_xlabel('Mai√∫sculas')\n",
        "axes[0,2].legend()\n",
        "\n",
        "axes[1,0].hist(df[df['target']==0]['exclamation_count'], alpha=0.7, label='Ham', bins=20)\n",
        "axes[1,0].hist(df[df['target']==1]['exclamation_count'], alpha=0.7, label='Spam', bins=20)\n",
        "axes[1,0].set_title('Exclama√ß√µes')\n",
        "axes[1,0].set_xlabel('!')\n",
        "axes[1,0].legend()\n",
        "\n",
        "axes[1,1].hist(df[df['target']==0]['digit_count'], alpha=0.7, label='Ham', bins=20)\n",
        "axes[1,1].hist(df[df['target']==1]['digit_count'], alpha=0.7, label='Spam', bins=20)\n",
        "axes[1,1].set_title('D√≠gitos')\n",
        "axes[1,1].set_xlabel('D√≠gitos')\n",
        "axes[1,1].legend()\n",
        "\n",
        "df['uppercase_ratio'] = df['uppercase_count'] / df['text_length'].replace(0, 1)\n",
        "axes[1,2].hist(df[df['target']==0]['uppercase_ratio'], alpha=0.7, label='Ham', bins=30)\n",
        "axes[1,2].hist(df[df['target']==1]['uppercase_ratio'], alpha=0.7, label='Spam', bins=30)\n",
        "axes[1,2].set_title('Propor√ß√£o de Mai√∫sculas')\n",
        "axes[1,2].set_xlabel('Propor√ß√£o')\n",
        "axes[1,2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pr√©-processamento de Texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', 'URL', text)\n",
        "    text = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', 'PHONE', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "print('Exemplo de pr√©-processamento:')\n",
        "print(df[['text', 'processed_text']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extra√ß√£o de Features Espec√≠ficas para Spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SpamFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.spam_keywords = [\n",
        "            'urgent', 'free', 'winner', 'won', 'prize', 'claim', 'click', 'limited',\n",
        "            'offer', 'discount', 'save', 'money', 'cash', 'bonus', 'congratulations',\n",
        "            'selected', 'exclusive', 'guaranteed', 'risk-free', 'act now', 'call now',\n",
        "            'text', 'sms', 'ringtone', 'viagra', 'lottery', 'credit', 'loan', 'debt',\n",
        "            'bank', 'account', 'verify', 'suspended', 'virus', 'antivirus', 'download',\n",
        "            'iphone', 'iphone!', 'computer', 'mobile', 'number', 'awarded', 'bonus',\n",
        "            'claim now', 'click here', 'limited time', 'exclusive offer'\n",
        "        ]\n",
        "        self.spam_patterns = [\n",
        "            r'\\b(?:URGENT|FREE|WINNER|PRIZE|CLAIM|CLICK|LIMITED|OFFER|BONUS|CONGRATULATIONS)\\b',\n",
        "            r'\\b(?:ACT NOW|CALL NOW|TEXT NOW|DOWNLOAD NOW)\\b',\n",
        "            r'\\b(?:YOUR (?:ACCOUNT|BANK|COMPUTER|MOBILE|NUMBER))\\b',\n",
        "            r'\\b(?:HAS BEEN (?:SUSPENDED|AWARDED|SELECTED))\\b',\n",
        "            r'\\b(?:NEEDS (?:VERIFICATION|DOWNLOAD|ANTIVIRUS))\\b',\n",
        "            r'\\b(?:FREE (?:RINGTONE|VIAGRA|CREDIT|LOTTERY|IPHONE))\\b',\n",
        "            r'\\b(?:WIN (?:PRIZE|MONEY|CASH|BONUS))\\b',\n",
        "            r'\\b(?:CONGRATULATIONS! YOU\\'VE)\\b',\n",
        "            r'\\b(?:URGENT: YOUR)\\b',\n",
        "            r'\\b(?:CLICK HERE TO)\\b'\n",
        "        ]\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        features = []\n",
        "        for text in X:\n",
        "            text_str = str(text).lower()\n",
        "            text_upper = str(text).upper()\n",
        "            feature_dict = {\n",
        "                'exclamation_count': text_str.count('!'),\n",
        "                'question_count': text_str.count('?'),\n",
        "                'uppercase_count': sum(1 for c in text if c.isupper()),\n",
        "                'digit_count': sum(1 for c in text if c.isdigit()),\n",
        "                'text_length': len(text),\n",
        "                'word_count': len(text_str.split()),\n",
        "                'spam_keyword_count': sum(1 for keyword in self.spam_keywords if keyword in text_str),\n",
        "                'spam_pattern_count': sum(1 for pattern in self.spam_patterns if re.search(pattern, text_upper)),\n",
        "                'has_urgent': 1 if 'urgent' in text_str else 0,\n",
        "                'has_free': 1 if 'free' in text_str else 0,\n",
        "                'has_winner': 1 if 'winner' in text_str or 'won' in text_str else 0,\n",
        "                'has_prize': 1 if 'prize' in text_str else 0,\n",
        "                'has_claim': 1 if 'claim' in text_str else 0,\n",
        "                'has_click': 1 if 'click' in text_str else 0,\n",
        "                'has_congratulations': 1 if 'congratulations' in text_str else 0,\n",
        "                'has_selected': 1 if 'selected' in text_str else 0,\n",
        "                'has_iphone': 1 if 'iphone' in text_str else 0,\n",
        "                'has_computer': 1 if 'computer' in text_str else 0,\n",
        "                'has_virus': 1 if 'virus' in text_str else 0,\n",
        "                'has_antivirus': 1 if 'antivirus' in text_str else 0,\n",
        "                'has_download': 1 if 'download' in text_str else 0,\n",
        "                'has_bank': 1 if 'bank' in text_str else 0,\n",
        "                'has_account': 1 if 'account' in text_str else 0,\n",
        "                'has_verify': 1 if 'verify' in text_str else 0,\n",
        "                'has_suspended': 1 if 'suspended' in text_str else 0,\n",
        "                'has_bonus': 1 if 'bonus' in text_str else 0,\n",
        "                'has_money': 1 if 'money' in text_str else 0,\n",
        "                'has_cash': 1 if 'cash' in text_str else 0,\n",
        "                'has_limited': 1 if 'limited' in text_str else 0,\n",
        "                'has_exclusive': 1 if 'exclusive' in text_str else 0,\n",
        "                'has_guaranteed': 1 if 'guaranteed' in text_str else 0,\n",
        "                'has_risk_free': 1 if 'risk-free' in text_str else 0,\n",
        "                'has_act_now': 1 if 'act now' in text_str else 0,\n",
        "                'has_call_now': 1 if 'call now' in text_str else 0,\n",
        "                'has_text_now': 1 if 'text now' in text_str else 0,\n",
        "                'has_ringtone': 1 if 'ringtone' in text_str else 0,\n",
        "                'has_viagra': 1 if 'viagra' in text_str else 0,\n",
        "                'has_lottery': 1 if 'lottery' in text_str else 0,\n",
        "                'has_credit': 1 if 'credit' in text_str else 0,\n",
        "                'has_loan': 1 if 'loan' in text_str else 0,\n",
        "                'has_debt': 1 if 'debt' in text_str else 0,\n",
        "                'has_sms': 1 if 'sms' in text_str else 0,\n",
        "                'has_offer': 1 if 'offer' in text_str else 0,\n",
        "                'has_discount': 1 if 'discount' in text_str else 0,\n",
        "                'has_save': 1 if 'save' in text_str else 0,\n",
        "            }\n",
        "            if len(text) > 0:\n",
        "                feature_dict['uppercase_ratio'] = feature_dict['uppercase_count'] / len(text)\n",
        "            else:\n",
        "                feature_dict['uppercase_ratio'] = 0\n",
        "            if feature_dict['word_count'] > 0:\n",
        "                feature_dict['avg_word_length'] = feature_dict['text_length'] / feature_dict['word_count']\n",
        "            else:\n",
        "                feature_dict['avg_word_length'] = 0\n",
        "            feature_dict['spam_score'] = (\n",
        "                feature_dict['spam_keyword_count'] * 2 +\n",
        "                feature_dict['spam_pattern_count'] * 3 +\n",
        "                feature_dict['exclamation_count'] * 0.5 +\n",
        "                feature_dict['uppercase_ratio'] * 10 +\n",
        "                feature_dict['has_urgent'] * 5 +\n",
        "                feature_dict['has_free'] * 3 +\n",
        "                feature_dict['has_winner'] * 4 +\n",
        "                feature_dict['has_prize'] * 4 +\n",
        "                feature_dict['has_claim'] * 3 +\n",
        "                feature_dict['has_congratulations'] * 4 +\n",
        "                feature_dict['has_selected'] * 3 +\n",
        "                feature_dict['has_iphone'] * 3 +\n",
        "                feature_dict['has_computer'] * 2 +\n",
        "                feature_dict['has_virus'] * 3 +\n",
        "                feature_dict['has_antivirus'] * 3 +\n",
        "                feature_dict['has_download'] * 2 +\n",
        "                feature_dict['has_bank'] * 3 +\n",
        "                feature_dict['has_account'] * 2 +\n",
        "                feature_dict['has_verify'] * 3 +\n",
        "                feature_dict['has_suspended'] * 4 +\n",
        "                feature_dict['has_bonus'] * 3 +\n",
        "                feature_dict['has_money'] * 2 +\n",
        "                feature_dict['has_cash'] * 2 +\n",
        "                feature_dict['has_limited'] * 2 +\n",
        "                feature_dict['has_exclusive'] * 2 +\n",
        "                feature_dict['has_guaranteed'] * 2 +\n",
        "                feature_dict['has_risk_free'] * 3 +\n",
        "                feature_dict['has_act_now'] * 4 +\n",
        "                feature_dict['has_call_now'] * 3 +\n",
        "                feature_dict['has_text_now'] * 3 +\n",
        "                feature_dict['has_ringtone'] * 3 +\n",
        "                feature_dict['has_viagra'] * 5 +\n",
        "                feature_dict['has_lottery'] * 4 +\n",
        "                feature_dict['has_credit'] * 2 +\n",
        "                feature_dict['has_loan'] * 2 +\n",
        "                feature_dict['has_debt'] * 2 +\n",
        "                feature_dict['has_sms'] * 2 +\n",
        "                feature_dict['has_offer'] * 2 +\n",
        "                feature_dict['has_discount'] * 2 +\n",
        "                feature_dict['has_save'] * 1\n",
        "            )\n",
        "            features.append(list(feature_dict.values()))\n",
        "        return np.array(features)\n",
        "\n",
        "# Exemplo de uso\n",
        "extractor = SpamFeatureExtractor()\n",
        "features = extractor.fit_transform(df['processed_text'])\n",
        "print('Shape das features extra√≠das:', features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Defini√ß√£o do Pipeline Robusto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_robust_pipeline():\n",
        "    tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2), min_df=2, max_df=0.95, stop_words='english')\n",
        "    spam_features = SpamFeatureExtractor()\n",
        "    feature_union = FeatureUnion([('tfidf', tfidf), ('spam_features', spam_features)])\n",
        "    classifier = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight='balanced')\n",
        "    pipeline = Pipeline([('features', feature_union), ('classifier', classifier)])\n",
        "    return pipeline\n",
        "\n",
        "pipeline = create_robust_pipeline()\n",
        "print('Pipeline robusto criado!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Treinamento e Avalia√ß√£o do Modelo Robusto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_text'], df['target'], test_size=0.2, random_state=42, stratify=df['target'])\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
        "plt.title('Matriz de Confus√£o - Modelo Robusto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.xlabel('Valor Predito')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Teste com Mensagens Problem√°ticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "problem_messages = [\n",
        "    \"CONGRATULATIONS! You've been selected for a free iPhone!\",\n",
        "    \"URGENT: Your computer has a virus! Download antivirus now!\",\n",
        "    \"Hi, how are you? Let's meet for coffee tomorrow.\",\n",
        "    \"URGENT! You have won a prize! Click here to claim!\",\n",
        "    \"FREE RINGTONE text FIRST to 87131 for a poly\",\n",
        "    \"Ok, I'll call you later\",\n",
        "    \"Thanks for your help yesterday\"\n",
        "]\n",
        "expected = [1, 1, 0, 1, 1, 0, 0]\n",
        "print('Testando mensagens problem√°ticas:')\n",
        "correct = 0\n",
        "for i, (msg, exp) in enumerate(zip(problem_messages, expected), 1):\n",
        "    processed_msg = preprocess_text(msg)\n",
        "    pred = pipeline.predict([processed_msg])[0]\n",
        "    prob = pipeline.predict_proba([processed_msg])[0][1]\n",
        "    result = 'SPAM' if pred == 1 else 'HAM'\n",
        "    expected_text = 'SPAM' if exp == 1 else 'HAM'\n",
        "    status = '‚úÖ' if pred == exp else '‚ùå'\n",
        "    if pred == exp:\n",
        "        correct += 1\n",
        "    print(f'{i}. {status} {result:4s} (prob: {prob:.3f}) - {expected_text:4s}')\n",
        "    print(f'    \"{msg[:60]}{'...' if len(msg) > 60 else ''}\"')\n",
        "    print()\n",
        "accuracy = correct / len(problem_messages)\n",
        "print(f'Resultado: {correct}/{len(problem_messages)} corretos ({accuracy:.1%})')\n",
        "if accuracy >= 0.9:\n",
        "    print('üéâ Modelo robusto funcionando muito bem!')\n",
        "elif accuracy >= 0.8:\n",
        "    print('‚úÖ Modelo robusto funcionando bem!')\n",
        "else:\n",
        "    print('‚ö†Ô∏è  Modelo ainda precisa de ajustes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Exporta√ß√£o do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar o modelo treinado usando joblib no diret√≥rio pai\n",
        "model_filename = '../robust_spam_model.joblib'\n",
        "joblib.dump(pipeline, model_filename)\n",
        "print(f'‚úÖ Modelo exportado com sucesso: {model_filename}')\n",
        "\n",
        "# Informa√ß√µes sobre o modelo salvo\n",
        "print(f'\\nüìä Informa√ß√µes do modelo:')\n",
        "print(f'- Arquivo: {model_filename}')\n",
        "print(f'- Tamanho: {len(joblib.dumps(pipeline)) / 1024 / 1024:.2f} MB')\n",
        "print(f'- Tipo: Pipeline com TF-IDF + Random Forest')\n",
        "print(f'- Features: TF-IDF + Spam Features Extractor')\n",
        "print(f'- Classificador: Random Forest (200 √°rvores)')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
